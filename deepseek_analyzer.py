#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek AI æ–‡æœ¬åˆ†ææ¨¡å—
ä½¿ç”¨DeepSeek APIå¯¹è‚¡å§å¸–å­è¿›è¡Œæ·±åº¦åˆ†æ
"""

import pandas as pd
import json
import requests
import time
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')


class DeepSeekAnalyzer:
    """DeepSeek AIåˆ†æå™¨"""
    
    def __init__(self, api_key=None, api_base="https://api.deepseek.com/v1"):
        """
        åˆå§‹åŒ–DeepSeekåˆ†æå™¨
        
        å‚æ•°:
            api_key: DeepSeek APIå¯†é’¥
            api_base: APIåŸºç¡€URL
        """
        self.api_key = api_key or "YOUR_DEEPSEEK_API_KEY"  # éœ€è¦æ›¿æ¢ä¸ºå®é™…çš„API Key
        self.api_base = api_base
        self.model = "deepseek-chat"  # ä½¿ç”¨DeepSeek Chatæ¨¡å‹
        
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """ä½ ç°åœ¨æ˜¯ä¸€ä¸ªèµ„æ·±é‡‘èåšå¼ˆä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œå¹¶æŒ‰è¦æ±‚è¾“å‡ºã€‚

åˆ†æé€»è¾‘ï¼š
1. æå–æ ‡çš„ï¼šè¯†åˆ«æåŠçš„å…·ä½“è‚¡ç¥¨ä»£ç æˆ–ç®€ç§°
2. æƒ…ç»ªé‡åŒ–ï¼šç»™å‡º -1.0 (æåº¦ææ…Œ) åˆ° 1.0 (æåº¦ä¹è§‚) çš„åˆ†å€¼
3. é€»è¾‘æå–ï¼šç”¨ä¸€å¥è¯æ€»ç»“å¸–å­çš„æ ¸å¿ƒè®ºç‚¹ï¼ˆå¦‚ï¼šé¢„æœŸé‡ç»„ã€æŠ€æœ¯ä½è¶…å–ã€å¤§å•å‹ç›˜ï¼‰
4. ç½®ä¿¡åº¦è¯„åˆ†ï¼š0.0 åˆ° 1.0ã€‚åŒ…å«æ•°æ®æ”¯æ’‘çš„ç»™é«˜åˆ†ï¼Œçº¯è°©éª‚ç»™ 0

è¾“å‡ºæ ¼å¼ï¼š
è¯·ä»…è¾“å‡º JSON æ ¼å¼ï¼Œå­—æ®µåŒ…å«ï¼š
- stock_name: è‚¡ç¥¨åç§°æˆ–ä»£ç 
- sentiment_score: æƒ…ç»ªåˆ†å€¼ (-1.0 åˆ° 1.0)
- key_logic: æ ¸å¿ƒè®ºç‚¹ï¼ˆä¸€å¥è¯ï¼‰
- confidence_level: ç½®ä¿¡åº¦ (0.0 åˆ° 1.0)

å¦‚æœæ–‡æœ¬ä¸­æåˆ°å¤šåªè‚¡ç¥¨ï¼Œè¯·ä¸ºæ¯åªè‚¡ç¥¨è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œç”¨æ•°ç»„åŒ…è£¹ã€‚
å¦‚æœæ— æ³•è¯†åˆ«è‚¡ç¥¨æˆ–æ–‡æœ¬è´¨é‡å¤ªä½ï¼Œè¿”å›ç©ºæ•°ç»„ []ã€‚"""
    
    def analyze_posts(self, posts_df, batch_size=10, delay=1):
        """
        åˆ†æè‚¡å§å¸–å­
        
        å‚æ•°:
            posts_df: åŒ…å«å¸–å­çš„DataFrame
            batch_size: æ¯æ‰¹å¤„ç†çš„å¸–å­æ•°é‡
            delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
            
        è¿”å›:
            DataFrame: åŒ…å«AIåˆ†æç»“æœçš„æ•°æ®
        """
        if posts_df.empty:
            print("è¾“å…¥æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
        
        print(f"å¼€å§‹ä½¿ç”¨DeepSeek AIåˆ†æ {len(posts_df)} æ¡å¸–å­...")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}, è¯·æ±‚é—´éš”: {delay}ç§’")
        
        all_results = []
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(posts_df), batch_size):
            batch = posts_df.iloc[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(posts_df) + batch_size - 1) // batch_size
            
            print(f"\nå¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}...")
            
            for idx, row in batch.iterrows():
                try:
                    # å‡†å¤‡è¾“å…¥æ–‡æœ¬
                    title = str(row.get('æ ‡é¢˜', ''))
                    content = str(row.get('å†…å®¹', ''))
                    
                    # è°ƒç”¨DeepSeek API
                    result = self._analyze_single_post(title, content)
                    
                    if result:
                        # æ·»åŠ åŸå§‹ä¿¡æ¯
                        for item in result:
                            item['åŸå§‹æ ‡é¢˜'] = title
                            item['åŸå§‹å†…å®¹'] = content[:100] + '...' if len(content) > 100 else content
                            item['å¸–å­é“¾æ¥'] = row.get('å¸–å­é“¾æ¥', '')
                            item['å‘å¸ƒæ—¶é—´'] = row.get('å‘å¸ƒæ—¶é—´', '')
                            all_results.append(item)
                        
                        print(f"  âœ“ ç¬¬ {idx+1} æ¡: è¯†åˆ«åˆ° {len(result)} ä¸ªæ ‡çš„")
                    else:
                        print(f"  Ã— ç¬¬ {idx+1} æ¡: æœªè¯†åˆ«åˆ°æœ‰æ•ˆä¿¡æ¯")
                    
                    # å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
                    time.sleep(delay)
                    
                except Exception as e:
                    print(f"  Ã— ç¬¬ {idx+1} æ¡åˆ†æå¤±è´¥: {e}")
                    continue
        
        if all_results:
            result_df = pd.DataFrame(all_results)
            print(f"\nâœ“ åˆ†æå®Œæˆï¼Œå…±è¯†åˆ« {len(result_df)} æ¡æœ‰æ•ˆä¿¡æ¯")
            return result_df
        else:
            print("\nÃ— æœªè¯†åˆ«åˆ°æœ‰æ•ˆä¿¡æ¯")
            return pd.DataFrame()
    
    def _analyze_single_post(self, title, content):
        """
        åˆ†æå•æ¡å¸–å­
        
        å‚æ•°:
            title: å¸–å­æ ‡é¢˜
            content: å¸–å­å†…å®¹
            
        è¿”å›:
            list: åˆ†æç»“æœåˆ—è¡¨
        """
        # æ„å»ºç”¨æˆ·è¾“å…¥
        user_input = f"æ ‡é¢˜: {title}\nå†…å®¹: {content}"
        
        # è°ƒç”¨API
        try:
            response = self._call_deepseek_api(user_input)
            
            if response:
                # è§£æJSONç»“æœ
                try:
                    # å°è¯•ç›´æ¥è§£æ
                    result = json.loads(response)
                    
                    # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªå¯¹è±¡ï¼Œè½¬ä¸ºæ•°ç»„
                    if isinstance(result, dict):
                        result = [result]
                    
                    # éªŒè¯ç»“æœæ ¼å¼
                    validated_results = []
                    for item in result:
                        if self._validate_result(item):
                            validated_results.append(item)
                    
                    return validated_results
                    
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯æ ‡å‡†JSONï¼Œå°è¯•æå–
                    print(f"    è­¦å‘Š: JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”: {response[:100]}...")
                    return []
            
            return []
            
        except Exception as e:
            print(f"    APIè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def _call_deepseek_api(self, user_input):
        """
        è°ƒç”¨DeepSeek API
        
        å‚æ•°:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        è¿”å›:
            str: APIå“åº”å†…å®¹
        """
        url = f"{self.api_base}/chat/completions"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_input}
            ],
            "temperature": 0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
            "max_tokens": 500
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            
            # æå–å“åº”å†…å®¹
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                return content.strip()
            
            return None
            
        except requests.exceptions.RequestException as e:
            print(f"    APIè¯·æ±‚é”™è¯¯: {e}")
            return None
    
    def _validate_result(self, item):
        """éªŒè¯ç»“æœæ ¼å¼"""
        required_fields = ['stock_name', 'sentiment_score', 'key_logic', 'confidence_level']
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in required_fields:
            if field not in item:
                return False
        
        # éªŒè¯æ•°å€¼èŒƒå›´
        try:
            sentiment = float(item['sentiment_score'])
            confidence = float(item['confidence_level'])
            
            if not (-1.0 <= sentiment <= 1.0):
                return False
            if not (0.0 <= confidence <= 1.0):
                return False
                
        except (ValueError, TypeError):
            return False
        
        return True
    
    def generate_analysis_report(self, analysis_df):
        """ç”ŸæˆAIåˆ†ææŠ¥å‘Š"""
        if analysis_df.empty:
            return "æœªè·å–åˆ°AIåˆ†æç»“æœ"
        
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("DeepSeek AI æ·±åº¦åˆ†ææŠ¥å‘Š")
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        report_lines.append("=" * 80)
        report_lines.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        report_lines.append("ã€åˆ†ææ¦‚è§ˆã€‘")
        report_lines.append(f"åˆ†ææ ‡çš„æ€»æ•°: {len(analysis_df)}")
        report_lines.append(f"å¹³å‡æƒ…ç»ªåˆ†å€¼: {analysis_df['sentiment_score'].mean():.2f}")
        report_lines.append(f"å¹³å‡ç½®ä¿¡åº¦: {analysis_df['confidence_level'].mean():.2f}")
        report_lines.append("")
        
        # æƒ…ç»ªåˆ†å¸ƒ
        positive = len(analysis_df[analysis_df['sentiment_score'] > 0.3])
        neutral = len(analysis_df[(analysis_df['sentiment_score'] >= -0.3) & (analysis_df['sentiment_score'] <= 0.3)])
        negative = len(analysis_df[analysis_df['sentiment_score'] < -0.3])
        
        report_lines.append("ã€å¸‚åœºæƒ…ç»ªåˆ†å¸ƒã€‘")
        report_lines.append(f"  ä¹è§‚æƒ…ç»ª: {positive} æ¡ ({positive/len(analysis_df)*100:.1f}%)")
        report_lines.append(f"  ä¸­æ€§æƒ…ç»ª: {neutral} æ¡ ({neutral/len(analysis_df)*100:.1f}%)")
        report_lines.append(f"  æ‚²è§‚æƒ…ç»ª: {negative} æ¡ ({negative/len(analysis_df)*100:.1f}%)")
        report_lines.append("")
        
        # é«˜ç½®ä¿¡åº¦æ ‡çš„
        high_confidence = analysis_df[analysis_df['confidence_level'] >= 0.7].sort_values(
            'confidence_level', ascending=False
        )
        
        if not high_confidence.empty:
            report_lines.append("ã€é«˜ç½®ä¿¡åº¦æ ‡çš„ TOP 10ã€‘")
            report_lines.append("-" * 80)
            
            for idx, row in high_confidence.head(10).iterrows():
                sentiment_label = self._get_sentiment_label(row['sentiment_score'])
                
                report_lines.append(f"\n{idx+1}. {row['stock_name']}")
                report_lines.append(f"   æƒ…ç»ª: {sentiment_label} ({row['sentiment_score']:.2f})")
                report_lines.append(f"   ç½®ä¿¡åº¦: {row['confidence_level']:.2f}")
                report_lines.append(f"   æ ¸å¿ƒé€»è¾‘: {row['key_logic']}")
                report_lines.append(f"   åŸå§‹æ ‡é¢˜: {row['åŸå§‹æ ‡é¢˜']}")
        
        report_lines.append("")
        report_lines.append("=" * 80)
        
        return "\n".join(report_lines)
    
    def _get_sentiment_label(self, score):
        """è·å–æƒ…ç»ªæ ‡ç­¾"""
        if score >= 0.7:
            return "ğŸ”¥ æåº¦ä¹è§‚"
        elif score >= 0.3:
            return "ğŸ“ˆ ä¹è§‚"
        elif score >= -0.3:
            return "â¡ï¸  ä¸­æ€§"
        elif score >= -0.7:
            return "ğŸ“‰ æ‚²è§‚"
        else:
            return "â„ï¸  æåº¦ææ…Œ"


def test_deepseek_analyzer():
    """æµ‹è¯•DeepSeekåˆ†æå™¨"""
    print("æµ‹è¯•DeepSeek AIåˆ†æå™¨...")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = {
        'æ ‡é¢˜': [
            'å±±ä¸œé»„é‡‘çªç ´60æ—¥å‡çº¿ï¼ŒMACDé‡‘å‰ï¼Œä¸»åŠ›èµ„é‡‘å¤§å¹…æµå…¥',
            'ç´«é‡‘çŸ¿ä¸šä¸šç»©é¢„å‘Šè¶…é¢„æœŸï¼Œç¤¾ä¿åŸºé‡‘å¢æŒæ˜æ˜¾',
            'é»„é‡‘è‚¡è¦èµ·é£äº†ï¼å¿…æ¶¨ï¼å†²å†²å†²ï¼',
            'ä¸­é‡‘é»„é‡‘æ”¾é‡çªç ´ï¼Œæˆäº¤é‡æ˜¯å‰æ—¥3å€',
            'æŸé»„é‡‘è‚¡å¤§å•å‹ç›˜ï¼Œä¸»åŠ›å¸ç­¹è¿¹è±¡æ˜æ˜¾'
        ],
        'å†…å®¹': [
            'æŠ€æœ¯é¢çœ‹ï¼Œå±±ä¸œé»„é‡‘ä»Šæ—¥çªç ´60æ—¥å‡çº¿ï¼ŒMACDæŒ‡æ ‡é‡‘å‰å‘ä¸Šï¼ŒåŒæ—¶ä¸»åŠ›èµ„é‡‘å‡€æµå…¥1.5äº¿å…ƒã€‚',
            'ç´«é‡‘çŸ¿ä¸šå‘å¸ƒä¸šç»©é¢„å‘Šï¼Œé¢„è®¡å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿45%ï¼Œè¶…å‡ºå¸‚åœºé¢„æœŸã€‚ç¤¾ä¿åŸºé‡‘å¢æŒ500ä¸‡è‚¡ã€‚',
            'é»„é‡‘è‚¡å¿…æ¶¨ï¼Œå¤§å®¶èµ¶ç´§ä¸Šè½¦ï¼',
            'ä¸­é‡‘é»„é‡‘ä»Šæ—¥æ”¾é‡ä¸Šæ¶¨ï¼Œæˆäº¤é‡è¾¾åˆ°å‰æ—¥çš„3å€ï¼Œçªç ´å‰æœŸç®±ä½“ã€‚',
            'è§‚å¯Ÿåˆ°æŸé»„é‡‘è‚¡æœ‰æ˜æ˜¾çš„å¤§å•å‹ç›˜è¿¹è±¡ï¼Œä¸»åŠ›èµ„é‡‘åœ¨ä½ä½å¸ç­¹ã€‚'
        ],
        'å¸–å­é“¾æ¥': [''] * 5,
        'å‘å¸ƒæ—¶é—´': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')] * 5
    }
    
    test_df = pd.DataFrame(test_data)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DeepSeekAnalyzer()
    
    # æ£€æŸ¥API Key
    if analyzer.api_key == "YOUR_DEEPSEEK_API_KEY":
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½®DeepSeek API Key")
        print("è¯·åœ¨ä»£ç ä¸­è®¾ç½® api_key å‚æ•°æˆ–è®¾ç½®ç¯å¢ƒå˜é‡")
        print("\nä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿç»“æœ
        mock_results = create_mock_analysis_results()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = analyzer.generate_analysis_report(mock_results)
        print("\n" + report)
        
        # ä¿å­˜ç»“æœ
        filename = f"deepseek_analysis_mock_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        mock_results.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\næ¨¡æ‹Ÿç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        return mock_results
    
    # å®é™…è°ƒç”¨API
    print("\nå¼€å§‹è°ƒç”¨DeepSeek API...")
    analysis_df = analyzer.analyze_posts(test_df, batch_size=5, delay=1)
    
    if not analysis_df.empty:
        # ç”ŸæˆæŠ¥å‘Š
        report = analyzer.generate_analysis_report(analysis_df)
        print("\n" + report)
        
        # ä¿å­˜ç»“æœ
        filename = f"deepseek_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        analysis_df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        return analysis_df
    else:
        print("æœªè·å–åˆ°åˆ†æç»“æœ")
        return pd.DataFrame()


def create_mock_analysis_results():
    """åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
    mock_data = {
        'stock_name': [
            'å±±ä¸œé»„é‡‘(600547)',
            'ç´«é‡‘çŸ¿ä¸š(601899)',
            'ä¸­é‡‘é»„é‡‘(600489)',
            'æŸé»„é‡‘è‚¡'
        ],
        'sentiment_score': [0.75, 0.80, 0.60, 0.40],
        'key_logic': [
            'æŠ€æœ¯é¢çªç ´60æ—¥å‡çº¿ï¼ŒMACDé‡‘å‰ï¼Œä¸»åŠ›èµ„é‡‘å‡€æµå…¥1.5äº¿',
            'ä¸šç»©é¢„å‘Šè¶…é¢„æœŸï¼Œå‡€åˆ©æ¶¦åŒæ¯”å¢é•¿45%ï¼Œç¤¾ä¿åŸºé‡‘å¢æŒ',
            'æ”¾é‡çªç ´ï¼Œæˆäº¤é‡æ”¾å¤§3å€ï¼Œçªç ´å‰æœŸç®±ä½“',
            'å¤§å•å‹ç›˜ï¼Œä¸»åŠ›ä½ä½å¸ç­¹'
        ],
        'confidence_level': [0.85, 0.90, 0.75, 0.60],
        'åŸå§‹æ ‡é¢˜': [
            'å±±ä¸œé»„é‡‘çªç ´60æ—¥å‡çº¿ï¼ŒMACDé‡‘å‰ï¼Œä¸»åŠ›èµ„é‡‘å¤§å¹…æµå…¥',
            'ç´«é‡‘çŸ¿ä¸šä¸šç»©é¢„å‘Šè¶…é¢„æœŸï¼Œç¤¾ä¿åŸºé‡‘å¢æŒæ˜æ˜¾',
            'ä¸­é‡‘é»„é‡‘æ”¾é‡çªç ´ï¼Œæˆäº¤é‡æ˜¯å‰æ—¥3å€',
            'æŸé»„é‡‘è‚¡å¤§å•å‹ç›˜ï¼Œä¸»åŠ›å¸ç­¹è¿¹è±¡æ˜æ˜¾'
        ],
        'åŸå§‹å†…å®¹': [
            'æŠ€æœ¯é¢çœ‹ï¼Œå±±ä¸œé»„é‡‘ä»Šæ—¥çªç ´60æ—¥å‡çº¿ï¼ŒMACDæŒ‡æ ‡é‡‘å‰å‘ä¸Š...',
            'ç´«é‡‘çŸ¿ä¸šå‘å¸ƒä¸šç»©é¢„å‘Šï¼Œé¢„è®¡å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿45%...',
            'ä¸­é‡‘é»„é‡‘ä»Šæ—¥æ”¾é‡ä¸Šæ¶¨ï¼Œæˆäº¤é‡è¾¾åˆ°å‰æ—¥çš„3å€...',
            'è§‚å¯Ÿåˆ°æŸé»„é‡‘è‚¡æœ‰æ˜æ˜¾çš„å¤§å•å‹ç›˜è¿¹è±¡...'
        ],
        'å¸–å­é“¾æ¥': [''] * 4,
        'å‘å¸ƒæ—¶é—´': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')] * 4
    }
    
    return pd.DataFrame(mock_data)


if __name__ == "__main__":
    test_deepseek_analyzer()